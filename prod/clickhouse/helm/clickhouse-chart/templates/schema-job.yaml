apiVersion: batch/v1
kind: Job
metadata:
  name: clickhouse-schema-init
  annotations:
    argocd.argoproj.io/hook: PostSync
    argocd.argoproj.io/hook-delete-policy: BeforeHookCreation
spec:
  backoffLimit: 10
  template:
    metadata:
      labels:
        app: clickhouse-schema-init
    spec:
      restartPolicy: OnFailure
      {{- with .Values.clickhouse.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.clickhouse.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      initContainers:
        - name: wait-for-clickhouse
          image: curlimages/curl:latest
          command:
            - /bin/sh
            - -c
            - |
              echo "Waiting for ClickHouse to be ready..."
              until curl -sf "http://clickhouse-{{ .Values.clusterName }}.{{ .Release.Namespace }}.svc.cluster.local:8123/ping"; do
                echo "ClickHouse not ready, retrying in 10s..."
                sleep 10
              done
              echo "ClickHouse is ready!"
      containers:
        - name: schema-init
          image: {{ .Values.clickhouse.image }}
          command:
            - /bin/sh
            - -c
            - |
              set -e
              CH_HOST="clickhouse-{{ .Values.clusterName }}.{{ .Release.Namespace }}.svc.cluster.local"
              CH_OPTS="--host $CH_HOST --port 9000 --user default --password {{ .Values.users.defaultPassword }}"

              echo "==> Creating database..."
              clickhouse-client $CH_OPTS --query "CREATE DATABASE IF NOT EXISTS cortex ON CLUSTER {{ .Values.clusterName }}"

              echo "==> Creating cortex_logs table..."
              clickhouse-client $CH_OPTS --query "
              CREATE TABLE IF NOT EXISTS cortex.cortex_logs ON CLUSTER {{ .Values.clusterName }} (
                  timestamp DateTime64(3, 'UTC') CODEC(Delta, ZSTD(1)),
                  level LowCardinality(String),
                  service_name LowCardinality(String),
                  environment LowCardinality(String),
                  hostname LowCardinality(String),
                  message String CODEC(ZSTD(3)),
                  log_type LowCardinality(String) DEFAULT 'internal',
                  correlation_id Nullable(String) CODEC(ZSTD(1)),
                  http_method LowCardinality(String),
                  http_path String CODEC(ZSTD(1)),
                  http_status Nullable(UInt16) CODEC(T64, ZSTD(1)),
                  http_duration_ms Nullable(UInt32) CODEC(T64, ZSTD(1)),
                  user_id Nullable(String) CODEC(ZSTD(1)),
                  tenant_id Nullable(String) CODEC(ZSTD(1)),
                  sub_tenant_id Nullable(String) CODEC(ZSTD(1)),
                  request_body Nullable(String) CODEC(ZSTD(3)),
                  client_ip Nullable(IPv6),
                  user_agent LowCardinality(String),
                  error_type LowCardinality(String),
                  error_message String CODEC(ZSTD(3)),
                  stack_trace String CODEC(ZSTD(3)),
                  operation LowCardinality(String),
                  result_count Nullable(UInt32),
                  event LowCardinality(String),
                  k8s_cluster LowCardinality(String) DEFAULT 'local-dev',
                  k8s_node_name LowCardinality(String) DEFAULT 'local-dev',
                  k8s_namespace LowCardinality(String) DEFAULT 'local-dev',
                  k8s_pod_name String DEFAULT 'local-dev' CODEC(ZSTD(1)),
                  k8s_pod_uid String DEFAULT 'local-dev' CODEC(ZSTD(1)),
                  k8s_container_name LowCardinality(String) DEFAULT 'local-dev',
                  k8s_container_image String DEFAULT 'local-dev' CODEC(ZSTD(1)),
                  k8s_labels Map(LowCardinality(String), String) CODEC(ZSTD(1)),
                  agent_version LowCardinality(String),
                  attributes Map(LowCardinality(String), String) CODEC(ZSTD(1)),
                  INDEX idx_message message TYPE tokenbf_v1(32768, 3, 0) GRANULARITY 1,
                  INDEX idx_correlation_id correlation_id TYPE bloom_filter GRANULARITY 4,
                  INDEX idx_user_id user_id TYPE bloom_filter GRANULARITY 4,
                  INDEX idx_http_path http_path TYPE bloom_filter GRANULARITY 4
              ) ENGINE = ReplicatedMergeTree('/clickhouse/tables/{shard}/cortex/cortex_logs', '{replica}')
              PARTITION BY toYYYYMM(timestamp)
              ORDER BY (service_name, environment, level, timestamp)
              TTL toDateTime(timestamp) + INTERVAL 28 DAY WHERE level IN ('debug', 'info'),
                  toDateTime(timestamp) + INTERVAL 30 DAY
              "

              echo "==> Creating cortex_logs_distributed table..."
              clickhouse-client $CH_OPTS --query "
              CREATE TABLE IF NOT EXISTS cortex.cortex_logs_distributed ON CLUSTER {{ .Values.clusterName }}
              AS cortex.cortex_logs
              ENGINE = Distributed({{ .Values.clusterName }}, cortex, cortex_logs, rand())
              "

              echo "==> Setting system log TTLs..."
              clickhouse-client $CH_OPTS --query "ALTER TABLE system.query_log MODIFY TTL event_time + INTERVAL 3 DAY" 2>/dev/null || true
              clickhouse-client $CH_OPTS --query "ALTER TABLE system.part_log MODIFY TTL event_time + INTERVAL 3 DAY" 2>/dev/null || true

              echo "==> Schema initialization complete!"
          resources:
            requests:
              cpu: 100m
              memory: 128Mi
            limits:
              cpu: 500m
              memory: 256Mi
